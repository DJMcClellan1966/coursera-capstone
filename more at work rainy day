---
title: "using tm"
author: "DJM"
date: "October 29, 2015"
output: html_document
---
Using TM package vignette
```{r}
setwd("~/R/capstone/capstone") #set directory where files are located
rm(list=ls())  #remove any old files for clarity
library(rjson) #yelp data is in json format
path <- "yelp_academic_dataset_review.json" #create path to file
con <- file(path, "r") #connect to file
lines <- readLines(con, n = 15000)  #read data as lines since it is so large only read 25000 lines       
review <- lapply(X = lines, fromJSON) #convert json to r language

class(review) # look at data to verify
length(review) #make sure that actually got all the data requested
review.df <- do.call(rbind, lapply(review, as.data.frame)) #convert to dataframe
write.csv(review.df, file = "yelp_review.csv", row.names = F) #create csv file

str(review.df)
review.df$stars <- factor(review.df$stars,
                             levels = c('1', '2', '3',
                                        '4', '5'),
                             labels = c("one",
                                        "two",
                                        "three",
                                        "four",
                                        "five"))
                    
count_bus_id <- count(review.df, 
                      business_id)
arrange(count_bus_id,desc(n))

data2 <- review.df[review.df$business_id %in%
                     c('mpDxBBGywUE6GRRKja3sBA'), ]
table(data2$stars)


library(dplyr)
votes <- mutate(data2,
                total.votes = votes.funny+    
                              votes.useful +
                              votes.cool)

dat2_stars <- select(votes,
                         total.votes,
                         stars,
                         text)

dat2_stars$stars <- as.factor(dat2_stars$stars)

str(dat2_stars$stars)
table(dat2_stars$stars)


```

```{r}
library(dplyr)
review_stars <- arrange(dat2_stars, stars) # arrange stars in order

worst <- filter(review_stars, stars == 1)
bad <- filter(review_stars, stars == 2)
okay <- filter(review_stars, stars == 3)
better <- filter(review_stars, stars == 4)
best <- filter(review_stars, stars == 5)

```

#worst
```{r}
library(tm) #package used to word with text
worst_text <- as.list(worst$text) #create a list of text only
worst_corpus <- Corpus(VectorSource(worst_text)) 
worst_corpus <- tm_map(worst_corpus,content_transformer(tolower)) #change all letters to lower case
worst_corpus <- tm_map(worst_corpus, PlainTextDocument) #need to change data into something to work with 
worst_corpus <- tm_map(worst_corpus, removePunctuation) #self explanatory
worst_corpus <- tm_map(worst_corpus,
                        function(x) removeWords(x, stopwords("SMART"))) # remove common words such as 'a'

par(mfrow=c(3,2))
wordcloud(worst_corpus, min.freq= 50,
          max.words = 300,
          color = brewer.pal(10,"Greys"),
          random.order = FALSE) #create wordcloud

 
```

#bad
```{r}
library(tm) #package used to word with text
bad_text <- as.list(bad$text) #create a list of text only
bad_corpus <- Corpus(VectorSource(bad_text)) 
bad_corpus <- tm_map(bad_corpus,content_transformer(tolower)) #change all letters to lower case
bad_corpus <- tm_map(bad_corpus, PlainTextDocument) #need to change data into something to work with 
bad_corpus <- tm_map(bad_corpus, removePunctuation) #self explanatory
bad_corpus <- tm_map(bad_corpus,
                        function(x) removeWords(x, stopwords("english"))) # remove common words such as 'a'

wordcloud(bad_corpus, min.freq= 500,
          max.words = 300,
          color = brewer.pal(10, 'BuPu'),
          random.order = FALSE) #create wordcloud


```
#okay
```{r}
library(tm) #package used to word with text
okay_text <- as.list(okay$text) #create a list of text only
okay_corpus <- Corpus(VectorSource(okay_text)) 
okay_corpus <- tm_map(okay_corpus,content_transformer(tolower)) #change all letters to lower case
okay_corpus <- tm_map(okay_corpus, PlainTextDocument) #need to change data into something to work with 
okay_corpus <- tm_map(okay_corpus, removePunctuation) #self explanatory
okay_corpus <- tm_map(okay_corpus,
                        function(x) removeWords(x, stopwords("english"))) # remove common words such as 'a'

wordcloud(okay_corpus, min.freq= 5,
          color = brewer.pal(9, "PuBuGn"),
          random.order = FALSE) #create wordcloud


```
#better
```{r}
library(tm) #package used to word with text
better_text <- as.list(better$text) #create a list of text only
better_corpus <- Corpus(VectorSource(better_text)) 
better_corpus <- tm_map(better_corpus,content_transformer(tolower)) #change all letters to lower case
better_corpus <- tm_map(better_corpus, PlainTextDocument) #need to change data into something to work with 
better_corpus <- tm_map(better_corpus, removePunctuation) #self explanatory
better_corpus <- tm_map(better_corpus,
                        function(x) removeWords(x, stopwords("english"))) # remove common words such as 'a'

wordcloud(better_corpus, min.freq= 5,
          color = brewer.pal(10, "YlOrBr"),
          random.order = FALSE) #create wordcloud


```

#Best
```{r}
library(tm) #package used to word with text
best_text <- as.list(best$text) #create a list of text only
best_corpus <- Corpus(VectorSource(best_text)) 
best_corpus <- tm_map(bad_corpus,content_transformer(tolower)) #change all letters to lower case
best_corpus <- tm_map(best_corpus, PlainTextDocument) #need to change data into something to work with 
best_corpus <- tm_map(best_corpus, removePunctuation) #self explanatory
best_corpus <- tm_map(best_corpus,
                        function(x) removeWords(x, stopwords("english"))) # remove common words such as 'a'
 
wordcloud(best_corpus, min.freq= 500,
          max.word = 300,
          color =  brewer.pal(8, "Dark2"),
          random.order = FALSE) #create wordcloud

```


```{r}
library(tm)

review_text <- paste(dat2_stars$text, collapse = " ")#pasting elements of vectors together
review_source <- Corpus(VectorSource(dat2_stars$text))

getTransformations()

corpus <- tm_map(review_source, content_transformer(tolower))
corpus <- tm_map(corpus, PlainTextDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, stopwords('english'))

stopwords('english')#see list of words removed

dtm <- DocumentTermMatrix(corpus)
dtmatrix <- as.matrix(dtm)
frequency <- colSums(dtmatrix)
frequency <- sort(frequency, decreasing = TRUE)
head(frequency)
tail(frequency)

library(wordcloud)
words <- names(frequency)
wordcloud(words[1:100], frequency[1:100])

stars_raw_train <- dat2_stars[1:176,]
stars_raw_test <- dat2_stars[177:252,]
                                 
dtm_train <- dtm[1:176,]
dtm_test <- dtm[177:252,]

corpus_train <- corpus[1:176]
corpus_test <- corpus[177:252]
```
#wordcloud
```{r}
library(wordcloud)
wordcloud(corpus_train, max.words = 40,
          random.order = FALSE,
          random.color = TRUE)
```

#Data Preparation
```{r}
freq.term <- findFreqTerms(dtm, lowfreq = 5)
head(freq.term)
tail(freq.term)

review_train <- TermDocumentMatrix(corpus_train,
                                   list(dictionary = freq.term))
review_test <- DocumentTermMatrix(corpus_test,
                                  list(dictionary = freq.term))

convert_counts <- function(x){
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1),
              labels = c('"No"', '"Yes"'))
  return(x)
}
```

##Naive Bayes
```{r}
review_train <- apply(review_train,MARGIN = 2,
                      convert_counts)
review_test <- apply(review_test, MARGIN = 1,
                     convert_counts)

library(e1071)
star_classifier <- naiveBayes(review_train,
                              stars_raw_train$stars,
                              laplace = 1)
star_test_predict <- predict(star_classifier,
                             review_test)
library(gmodels)
CrossTable(star_test_predict,
           stars_raw_test$stars,
           prop.chisq = FALSE,
           prop.t = FALSE,
           dnn = c("predicted", "actual"))

sparse.tdm <- removeSparseTerms(dtm, sparse = 0.95)
inspect(sparse.tdm)
sparse_review_scale <- scale(sparse.tdm)
review_dist <- dist(sparse_review_scale, method = "euclidean")
review_fit <- hclust(review_dist, method = "ward.D2")
plot(review_fit, main = "Cluster - Yelp Review")
groups <- cutree(review_fit, k = 5)
rect.hclust(review_fit, k =5, border = "blue")

```

